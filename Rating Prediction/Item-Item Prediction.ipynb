{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working directory\n",
    "working_directory = \"C:/Users/Eric/Google Drive/Uni/Assignments/Social and Information Network Analysis\\Assignment 3/ml-100k/\"\n",
    "#Get our data\n",
    "train_set = pd.read_csv(working_directory + \"u1.base.csv\", header=None, usecols=[0,1,2], names=['userId', 'movieId', 'rating'])\n",
    "test_set = pd.read_csv(working_directory + \"u1.test.csv\", header=None, usecols=[0,1,2], names=['userId', 'movieId', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorganise data\n",
    "def pivot(data, val, ind, col):\n",
    "    pivoted_data = pd.pivot_table(data, values=val, index=ind, columns=col, fill_value=0)\n",
    "    return pivoted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the training set\n",
    "def reduce_low_counts(pivot_data, amount):\n",
    "    pivot_data = pivot_data.replace(0, np.NaN)\n",
    "    pivot_data['counts'] = pivot_data.count(axis=1)\n",
    "    pivot_data = pivot_data[pivot_data['counts'] > amount]\n",
    "    pivot_data  = pivot_data.drop(columns=['counts'])\n",
    "    pivot_data  = pivot_data.fillna(0)\n",
    "    return pivot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate cosine value\n",
    "def cosine(data):\n",
    "    #Get cosine values\n",
    "    cosined_table = pd.DataFrame(cosine_similarity(data), index=data.index.values.tolist(), columns=data.index.values.tolist())\n",
    "    return cosined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test values with item-item CF weighted average\n",
    "def item_item_cf_weighted_avg(cosine_dataset, training_dataset_pivoted, testing_dataset, n):\n",
    "    predicted_values = []\n",
    "    for i in testing_dataset.index:\n",
    "        #Remove all diagonal values since they are all 1\n",
    "        np.fill_diagonal(cosine_dataset.values, 0)\n",
    "        #Get a user, movie from testing set and find the n most similar movies\n",
    "        current_user = testing_dataset.at[i, 'userId']\n",
    "        current_movie = testing_dataset.at[i, 'movieId']\n",
    "        \n",
    "        #Check if movie exists in the training dataset/cosine similarity matrix\n",
    "        if current_movie in cosine_dataset.columns:\n",
    "            current_df = cosine_dataset[[current_movie]].nlargest(n, current_movie)\n",
    "\n",
    "            #List of cosines\n",
    "            similar_movies_cosine = current_df[current_movie].values.tolist()\n",
    "            #List of movies\n",
    "            similar_movies_id = current_df.index.values.tolist()\n",
    "            #Get numerator and denominator for weighted average\n",
    "            part_numerator = 0\n",
    "            part_denominator = 0\n",
    "            for j in range(n):\n",
    "                #Numerator - users rating for similar movie * movie cosine similarity - summed for number of similar movies\n",
    "                part_numerator = part_numerator + training_dataset_pivoted.at[similar_movies_id[j], current_user] * similar_movies_cosine[j]\n",
    "                #Denominoator\n",
    "                part_denominator = part_denominator + similar_movies_cosine[j]\n",
    "            #Round predicted value and add to list\n",
    "            predicted_values.append(round(part_numerator / part_denominator))\n",
    "        #Set rating as 2.5 if it doesn't exist in the testing set\n",
    "        else:\n",
    "            predicted_values.append(0)\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the training set stuff\n",
    "training_set_pivot = pivot(train_set, 'rating', 'movieId', 'userId')\n",
    "\n",
    "#Reduce the training set if we want (we didnt here)\n",
    "reduced_training_set = reduce_low_counts(training_set_pivot, 0)\n",
    "training_set_cosine = cosine(reduced_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the predicted and actual values\n",
    "predicted = item_item_cf_weighted_avg(training_set_cosine, reduced_training_set, test_set, 20)\n",
    "actual = test_set['rating'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change predicted to whole numbers\n",
    "predicted = np.array(predicted)\n",
    "predicted = predicted.astype(np.int64)\n",
    "predicted = predicted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse is: 2.7269121731364945\n",
      "recall is: 0.0562\n"
     ]
    }
   ],
   "source": [
    "#Calculate the rmse and recall\n",
    "rmse = mean_squared_error(actual, predicted, squared=False)\n",
    "print(\"rmse is: \" + str(rmse))\n",
    "recall = recall_score(actual, predicted, average='micro')\n",
    "print(\"recall is: \" + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
